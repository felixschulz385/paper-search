{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 1: Create a new Assistant with File Search Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "env_path = \"../../keys.env\"\n",
    "\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "project = os.getenv(\"PROJECT\")\n",
    "organization = os.getenv(\"ORGANIZATION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "client = OpenAI(\n",
    " organization=organization,\n",
    " project=project,\n",
    " api_key=api_key \n",
    ")\n",
    "\n",
    " \n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Research Paper Analyst\",\n",
    "  instructions=\"You are an scientific researcher in the area of health economics. Use your knowledge base to help answer questions about the health economics research papers.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Upload files and add them to a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.beta.vector_stores.create(name=\"Health Economics Research Papers\")\n",
    " \n",
    "file_paths = [\"test_pdfs/guidetti-et-al-2021-placebo-tests-for-the-impacts-of-air-pollution-on-health-the-challenge-of-limited-health-care.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "print(file_batch.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".upload_and_poll():\n",
    "1. Upload the file: The function uploads a file to the OpenAI vector store. The file could be in-memory (as bytes) or from a specified path.\n",
    "2. Poll for completion: After uploading, it checks (polls) whether the file has been successfully processed and indexed. This is useful in cases where the processing takes time, and you want to wait until the file is fully ready for use in tasks like document search or interaction with an assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Update the assistant to use the new Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Create a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "            Please analyze the documents in the vector store. \n",
    "            For these documents find the following information about the study design and return them in json format. Each\n",
    "            information you need to find is seperated by a ',' and short description of the metric is given inside '()'.\n",
    "            Here are the things you must find from the documents:  \n",
    "            Sample size (Number of participants in the study),\n",
    "            Intervention type (Description of the intervention (e.g., drug, policy change),\n",
    "            Randomization Method (Details on how participants were randomized),\n",
    "            Country/Region (Where the study was conducted)\n",
    "            Population/Demographics (Key demographic details (e.g., age group, gender, socio-economic status),           \n",
    "            Health Outcome Measured (Specific health outcome(s) focused on)\n",
    "               \"\"\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5: Create a run and check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information extracted from the document, here is the study design summary in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Sample size\": \"89,492 observations\",\n",
      "  \"Intervention type\": \"Air pollution exposure (measuring PM10 levels) as an indicator of health impacts\",\n",
      "  \"Randomization Method\": \"Wind speed used as an instrument to address endogenous exposure to air pollution\",\n",
      "  \"Country/Region\": \"Sao Paulo Metropolitan Area, Brazil\",\n",
      "  \"Population/Demographics\": \"Children aged one to five years\",\n",
      "  \"Health Outcome Measured\": \"Pediatric hospitalizations for respiratory diseases including asthma and pneumonia\"\n",
      "}\n",
      "```\n",
      "\n",
      "These details are derived from the study focusing on air pollution's impact on health within the Sao Paulo Metropolitan Area, where data was collected between 2015 and 2017[0].\n",
      "[0] guidetti-et-al-2021-placebo-tests-for-the-impacts-of-air-pollution-on-health-the-challenge-of-limited-health-care.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
